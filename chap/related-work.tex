\chapter{研究现状和相关工作}
本章介绍研究现状和相关工作。

\section{视频流媒体领域的研究现状}

视频流媒体的研究可以从系统模块的角度分为几个方面。一是数据源端，即视频编码的研究，如何提高压缩率，如何提高码流的可伸缩性。二是传输过程，如何改善网络状况，如何充分合理利用带宽资源。三是客户终端，如何快速解码和更好的显示。

\section{SVC码流截取}

\subsection{问题描述}

码流截取是从一个完整的SVC码流中抽取所有数据包的一个子集，得到一个更低码率的子流的过程。图\ref{fig:Bitstream-Extraction}展示了一个SVC码流的结构，以及从中截取子流的一种可能的方式。
可以看到，该码流中的数据包被分为了不同的层。时间层（T0～T3）反映了各帧之间的参考或依赖关系。图形上方的箭头从被参考帧指向参考它（也就是依赖于它）的帧。质量层（Q0～Q2）反映了一帧之内的视频质量伸缩性。处于高层（也就是Q1和Q2层）的数据包可以被部分丢弃从而实现码流截取。图中的虚线表示了一个截取的例子。虚线上方的数据包全部被丢弃，只有虚线下方的数据包保留在截取出来的子流中。

\begin{figure}[h]
\centering
\includegraphics[width = 0.9\linewidth]{./figures/Bitstream-Extraction.jpg}
\caption{可伸缩视频码流截取 \label{fig:Bitstream-Extraction}}
\end{figure}

容易发现，SVC码流截取从本质上来看其实是一个组合优化问题。在所有的数据包中，我们希望在给定的码率限制下，选出一个最优的数据包组合，使得它们构成的子流具有最大的视频质量。更准确地说，这个问题与大家所熟知的“0-1背包问题”\footnote{http://en.wikipedia.org/wiki/Knapsack\_problem}在形式上是一致的。每个数据包可以看作是一个具有特定重量和价值的物品。这里的重量就是数据包的大小，价值就是它对重建视频质量的贡献。码流截取的过程就是决定每个数据包是否包含在最终的子流里。用“0-1背包问题”中的术语来说，就是选择将哪些物品放入背包中。

对于典型的“0-1背包问题”而言，其最优解可以用动态规划的方法得到。然而对于码流截取问题来说，这个方法是不可行的。主要原因在于数据包之间的依赖关系。首先，截取的数据包子集不能任意挑选，因为如果一个包被包含进了子流中，那么这个包所依赖的数据包也必须被包含进去，否则将无法正确解码。例如，在图\ref{fig:Bitstream-Extraction}中，我们不能只选择一帧中的Q2层数据包而丢弃同一帧的Q1层。其次，不同于“0-1背包问题”中定义良好的物品价值，码流截取问题中一个数据包对最终视频质量的贡献并不是明显且确定的。这是因为，数据包所在的帧在解码中是互相参考的，它们对视频质量的影响会互相干扰，对于不同的截取方案，每个数据包的实际贡献可能有所不同。事实上，除非实际进行一遍截取、解码、计算的操作，我们甚至无法准确地得到所截取出的子流的真实视频质量。这就使得SVC码流截取问题成为了一个复杂得多的问题。

\subsection{相关工作简介}

就我们所知，学术界没有人提出过一种确定能找到码流截取最优解的方法。当然可以用暴力穷举的方法来解决这个问题，但其复杂度显然是无法接受的。相关的工作都是尽可能用较低的计算量获得较好的次优解。下面对SVC码流截取的相关工作做简要的介绍。

Amonou等人\supercite{Amonou2007}提出了一个基于“Quality Layers”的码流截取方案。这一方案被SVC参考软件JSVM\supercite{JSVM}所采用，而且取得了比JSVM中的基本截取器更好的性能。在Amonou等人的方案中计算了一个“Quality Layers”（简称QL）值，它反映了一个数据包的码率失真影响，据此进行截取能得到率失真优化过的结果。但估计一个数据包的失真影响是一个计算量非常大的过程，而且失真估计的准确性也有提高的空间。因此，后续的工作提出的失真模型一方面是降低复杂度，另一方面是进一步提高准确度。Sun等人\supercite{Sun2009}和Maani等人\supercite{Maani2009}所构造的模型都是基于帧间的误差漂移来计算失真。孙等人的模型在性能方面几乎与JSVM相当，但计算复杂度却大大减少。而Maani等人的模型取得了比JSVM更高的估计准确度，但是由于其是基于训练的，为了得到更鲁棒的模型参数，需要更大的计算量。

Ramanathan等人\supercite{Ramanathan2012}提出了一个“Quality Metadata”的概念来用于码流截取，这与上面所说的“Quality Layers”是同样的思想，只是计算方法有所差别。Yang等人\supercite{Yang2013}提出了一个基于模拟退火的方法来解决码流截取问题。因为码流截取从另一个角度看是丢弃数据包的过程，丢弃的先后顺序可以认为是这些数据包的优先级。于是一些研究者从赋优先级的角度来提出相应的算法。例如，Lim等人\supercite{Lim2006}把SVC码流视为树形结构并据此来为每个数据包赋予优先级，而Zhu等人\supercite{Zhu2011}则采用拉格朗日乘子方法计算优先级值。在这些已有的工作中，失真估计的准确性都显著地影响最终结果。因此，提出简单有效的误差或失真模型对于码流截取的研究至关重要。这正是本文的创新点之一。


\section{传输中的码率自适应}

\subsection{问题描述}

在数据源具备码率可变的前提条件之后，实际传输时就可以根据带宽来调整发送的速率。改变码率去适应带宽的变化，这就是所谓的码率自适应问题。对于一个码率自适应算法，有三个最基本的目标。这三个目标可以用来衡量自适应算法的效果，也是设计算法时需要考虑的方面。下面分别进行描述。

首先是要确保视频播放的连续性。在流媒体系统中，一旦视频开始播放，每个数据包都有了自己的显示时间。这个时间也决定了传输的截止时间。如果这个数据包没有在截止时间前达到客户端，那么客户端播放器就会因缺少数据而暂停。这就是用户所遇到的卡顿现象，应该努力避免。

第二个目标是保持视频质量的平滑性。网络条件变化可能比较剧烈，但视频质量应该尽可能维持在一个比较稳定的水平。因为频繁的质量调整会给用户带来反感。举例来说，当用户适应了较低的质量后，突然调高质量并在短时间内又调低，给用户的体验还不如不调整。

第三个目标时要使视频平均质量尽可能高，也就是要充分利用可用带宽。假设我们一直发送较低码率的视频流，那么既能保证播放的连续性又不存在平滑性的问题。虽然第一和第二个目标都达到了，但较低的视频质量显然不是用户满意的选择。

综上所述，在视频流媒体的码率自适应研究中，保证播放流畅是最基本的要求，同时视频的高质量和平滑性也是所追求的指标。

\subsection{相关工作简介}

保证播放流畅的研究工作主要集中于如何选择和调度视频数据包。Gao等人\supercite{Gao2006}提出的调度策略首先确保重要性较高的数据优先发送，而对于重要性相同的数据包，播放时间最早的首先发送。Schier等人的工作\supercite{Schierl2010}也与此类似，把视频数据放在具有不同优先级的缓冲区中，通过调整优先级来确保数据及时发送。

上面的工作都是针对SVC流媒体系统进行的。但近年来具有代表性的视频自适应传输方案是HTTP动态自适应流媒体（DASH）\supercite{Sodagar2011}。DASH系统在服务器端提供不同码率的多个码流切片，客户端在某个时间段内可以选择性地接收这几个码流中任何一个的切片，通过在多码流之间切换来动态适应带宽波动。这就涉及如何制定码率调整策略，即码率自适应算法的设计。国内外对此已经有了不少研究。例如，Akhshabi等人\supercite{Akhshabi2012}分析了来自商业公司和开源社区的多个DASH客户端播放器的自适应行为，比较了他们之间性能的优缺点。张辉帅等人\supercite{Zhang2013}提出了一种基于拉模式的码率自适应算法，利用滑动窗口分析最近若干分片的下载时间，基于此来选择最合适的码流。Huang等人\supercite{Huang2015}结合了缓冲区的状态和对带宽容量的估计这两个判据来做如何调整码率的决策。Juluri\supercite{Juluri2015}等人考虑到每个分片数据量大小不同可能导致下载时间的差异，因此提出了一种提前查看分片信息的码率自适应算法。

这些已有的研究工作在一定程度上提高了传输效果，但大都是针对点播模式，没有考虑到直播模式下的特殊问题。目前实时性直播的应用越来越广，从某种程度上来说是一个更重要的模式。直播由于其数据是实时产生的，无法提前加载，因此与点播有所不同，需要进行针对性的研究，设计新的码率自适应算法。本文的工作不仅适用于点播系统，也能很容易应用到直播系统中。

\section{HEVC解码优化}

视频解码器优化的工作总是紧密结合视频编码标准而进行。在新一代国际视频编码标准HEVC推出以来，不少论文都针对其解码器实现和优化进行了研究。大部分已公开的研究工作都是在标准化组织所提供的参考软件HM\supercite{HM}的基础上进行的。在HM之外，我们所能查到的在正式发表文献中提出的独立解码器实现只有少数几个\supercite{Bossen-TCSVT2012,JCTVC-G988,JCTVC-H0693}。除了外在的性能报告和复杂度分析，这些文献中既没有给出任何技术细节或者源代码，也没有提供可以公开测试的演示程序。因此它们对HEVC的实际应用贡献并不大。Chavarrias等人\supercite{Chavarrias-TCE2013}提出了一个新的基于数字信号处理器（DSP）的HEVC解码器。但由于不是针对通用处理器平台，其应用局限性也比较大。本文主要关注的是在x86和ARM架构的通用处理器上的解码优化。下面分数据级和任务级两个方面对相关的工作进行介绍。

数据级解码器优化主要是采用单指令多数据（single-instruction-multiple-data，简称SIMD）的处理器指令集扩展来对解码过程中的特定计算模块进行加速。SIMD所适用的主要是运动校正、整数变换、去块滤波这些计算密集而规整的模块。不同编解码标准对这些模块的定义并不完全相同。就HEVC而言，它在运动校正时采用了8抽头的基于DCT的插值\supercite{JCTVC-F537}，而且在去块滤波之后加入了一个称为采样自适应偏移（sample adaptive offset，简称SAO）的新操作\supercite{Fu-TCSVT2012}。由于SIMD算法的设计与这些模块的操作密切相关，因此针对以前标准设计的数据级解码优化算法\supercite{Casalino-ICMCS1999,Lappalainen-TCSVT2003,Malvar-TCSVT2003,Chen-JVCIR2006,Pescador-TCE2009}都不再适用于HEVC。Yan等人\supercite{Yan-VCIP2012}在HM 4.0的基础上，采用SIMD技术对一些解码模块进行了加速。但随着标准文档和参考文件的更新，最终版本的HEVC相对于HM 4.0有些模块发生了变化，例如上述工作中所加速的自适应滤波\supercite{JCTVC-F303}最终被从标准中移除。因此，针对最新的标准需要重新设计和实现数据级的优化算法。

任务级解码器优化主要是通过多线程来并行执行解码任务，以充分利用多核CPU的并行特性。HEVC标准在设计的时候考虑了对任务级并行的支持，引入了分片（tiles）\supercite{JCTVC-E408}和波阵面并行处理（wavefront parallel processing，简称WPP）\supercite{JCTVC-E196}这两种技术。它们能够将解码分成互相独立的任务来同时执行，一定程度上可以提高整体解码速度。Chi等人\supercite{Chi-TCSVT2012}还基于WPP提出了一个称为“overlapped wavefront”的任务级并行优化技术，对于用WPP编码的视频码流取得了期望的解码加速比。然而需要指出的是，分片和WPP都是HEVC标准中的可选配置，如果视频码流在编码的时候没有开启这些选项，那么解码器就无法利用这两个新特性。从实用的角度来看，采用不依赖于这些特殊配置的帧级并行解码结构才具有更广泛的意义。这也正是本文工作所选择的方向。

